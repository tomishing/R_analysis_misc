[
  {
    "objectID": "penguin_sample.html",
    "href": "penguin_sample.html",
    "title": "penguins",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "penguin_sample.html#quarto",
    "href": "penguin_sample.html#quarto",
    "title": "penguins",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "penguin_sample.html#running-code",
    "href": "penguin_sample.html#running-code",
    "title": "penguins",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "penguin.html",
    "href": "penguin.html",
    "title": "Classification of Penguins species using Machine Learning Models",
    "section": "",
    "text": "Exclusively distributed in the Southern Hemisphere\nEighteen species are recognized\n\n\n\n\nPenguins distribution\n\n\n(source: Romos et al. BMC Genomics (2018) 1953, DOI 10.1186/s12864-017-4424-9; https://en.wikipedia.org/wiki/List_of_penguins)\n\n\n\n\n\n\n\n\n\nAdelie\n\n\n\n\n\n\n\nChinstrap\n\n\n\n\n\n\n\nGentoo\n\n\n\n\n\n\n\n\n\nAdelie distribution\n\n\n\n\n\n\n\nChinstrap distribution\n\n\n\n\n\n\n\nGentoo distribution\n\n\n\n\n\n(source: Andrew Shiva/Wikipedia; POLAR LITERACY, https://tinyurl.com/3h4xcr6n)\n\n\n\nGorman et al. (2014) provide part of their research data on three penguin species, aiming to investigate whether environmental variability is associated with differences in male and female pre-breeding foraging niches. Using this dataset, we examine whether habitat, morphological traits, and other features can help distinguish the species."
  },
  {
    "objectID": "penguin.html#introduction",
    "href": "penguin.html#introduction",
    "title": "Classification of Penguins species using Machine Learning Models",
    "section": "",
    "text": "Exclusively distributed in the Southern Hemisphere\nEighteen species are recognized\n\n\n\n\nPenguins distribution\n\n\n(source: Romos et al. BMC Genomics (2018) 1953, DOI 10.1186/s12864-017-4424-9; https://en.wikipedia.org/wiki/List_of_penguins)\n\n\n\n\n\n\n\n\n\nAdelie\n\n\n\n\n\n\n\nChinstrap\n\n\n\n\n\n\n\nGentoo\n\n\n\n\n\n\n\n\n\nAdelie distribution\n\n\n\n\n\n\n\nChinstrap distribution\n\n\n\n\n\n\n\nGentoo distribution\n\n\n\n\n\n(source: Andrew Shiva/Wikipedia; POLAR LITERACY, https://tinyurl.com/3h4xcr6n)\n\n\n\nGorman et al. (2014) provide part of their research data on three penguin species, aiming to investigate whether environmental variability is associated with differences in male and female pre-breeding foraging niches. Using this dataset, we examine whether habitat, morphological traits, and other features can help distinguish the species."
  },
  {
    "objectID": "penguin.html#methods",
    "href": "penguin.html#methods",
    "title": "Classification of Penguins species using Machine Learning Models",
    "section": "Methods",
    "text": "Methods\n\nData\nThe data were originally collected by Gorman and her collegues (see Gorman KB et al. (2014) PLOS ONE, 9(3): e90081. https://doi.org/10.1371/journal.pone.0090081 ) and were downloaded from Kaggle for the years 2021 to 2025 (https://tinyurl.com/mmy6ds5n). This dataset is already well curated, it contains no missing values, duplicates or null entries.\nData were collected in the three islands: Biscoe, Dream and Torgensen in Antarctica.\n (source: Gorman et al. 2014)\n\n\nImporting and exploring data\n\nlibrary(pacman)\np_load(tidyverse, skimr, gridExtra, GGally, corrplot, car)\n\nWe used the pacman library, which allows installing and loading libraries simultaneously, as an alternative to using install.packages() and library() separately.\n\ndf &lt;- read.csv(\"palmerpenguins_extended.csv\")\n\n\nExploring data\n\ndf %&gt;% glimpse\n\nRows: 3,430\nColumns: 11\n$ species           &lt;chr&gt; \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"Adelie\", \"A…\n$ island            &lt;chr&gt; \"Biscoe\", \"Biscoe\", \"Biscoe\", \"Biscoe\", \"Biscoe\", \"B…\n$ bill_length_mm    &lt;dbl&gt; 53.4, 49.3, 55.7, 38.0, 60.7, 35.7, 61.0, 66.1, 61.4…\n$ bill_depth_mm     &lt;dbl&gt; 17.8, 18.1, 16.6, 15.6, 17.9, 16.8, 20.8, 20.8, 19.9…\n$ flipper_length_mm &lt;dbl&gt; 219, 245, 226, 221, 177, 194, 211, 246, 270, 230, 27…\n$ body_mass_g       &lt;dbl&gt; 5687, 6811, 5388, 6262, 4811, 5266, 5961, 6653, 6722…\n$ sex               &lt;chr&gt; \"female\", \"female\", \"female\", \"female\", \"female\", \"f…\n$ diet              &lt;chr&gt; \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"fish\", \"fis…\n$ life_stage        &lt;chr&gt; \"adult\", \"adult\", \"adult\", \"adult\", \"juvenile\", \"juv…\n$ health_metrics    &lt;chr&gt; \"overweight\", \"overweight\", \"overweight\", \"overweigh…\n$ year              &lt;int&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021…\n\n\nThe dataset contains both numerical and categorical columns. It has 10 feartuers and 1 target column (it is the species column in this report), and 3,430 records.\n\nskim_s &lt;- skim(df)\nprint(skim_s)\n\n── Data Summary ────────────────────────\n                           Values\nName                       df    \nNumber of rows             3430  \nNumber of columns          11    \n_______________________          \nColumn type frequency:           \n  character                6     \n  numeric                  5     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable  n_missing complete_rate min max empty n_unique whitespace\n1 species                0             1   6   9     0        3          0\n2 island                 0             1   5   9     0        3          0\n3 sex                    0             1   4   6     0        2          0\n4 diet                   0             1   4   8     0        4          0\n5 life_stage             0             1   5   8     0        3          0\n6 health_metrics         0             1   7  11     0        3          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable     n_missing complete_rate   mean      sd     p0    p25    p50\n1 bill_length_mm            0             1   38.5   13.2    13.6   28.9   34.5\n2 bill_depth_mm             0             1   18.4    2.77    9.1   16.6   18.4\n3 flipper_length_mm         0             1  207.    28.9   140    185    203  \n4 body_mass_g               0             1 4835.  1311.   2477   3844.  4634. \n5 year                      0             1 2023.     1.31 2021   2022   2024  \n     p75    p100 hist \n1   46.6    88.2 ▃▇▃▂▁\n2   20.3    27.9 ▁▃▇▃▁\n3  226     308   ▂▇▅▂▁\n4 5622   10549   ▆▇▃▁▁\n5 2024    2025   ▃▆▆▇▇\n\n\n\n\nTarget\nThe target variable is penguin species, consisting of three classes, making this a multiclass classification problem. The dataset is slightly imbalanced, though not enough to require adjustment. Adelie penguins represented in the largest number of records, while Chinstrap penguins have the fewest.\n\ntable(df$species)\n\n\n   Adelie Chinstrap    Gentoo \n     1560       623      1247 \n\n\n\n\nNumeric data distribution\n\ndf$year &lt;- as.factor(df$year)\nnumeric_df &lt;- df[sapply(df, is.numeric)]\ndf_num_tar &lt;- data.frame(species = df$species, year = df$year, numeric_df)\n\n\ndf_l &lt;- df_num_tar %&gt;% pivot_longer(cols = 3:6, names_to = \"variables\", \n                                    values_to = \"values\")\np &lt;- df_l %&gt;% ggplot(aes(x = species, y = values)) + geom_boxplot() +\n  facet_wrap(~variables, scales = \"free_y\")\np\n\n\n\n\n\n\n\n\nThese figures show the outliers in all numerical features, bill depth, bill length, body mass and flipper length. Theoretically such outliers should be removed before applying linear models or distance-based models. However, I decided to keep them for now. If the performance of those models is poor or requires improvements, we will revisit this issue.\nThat said, data collected through fieldworks in harsh environment are rare, and the outliers often carry valuable ecological information. Therefore, they should not be removed unless these are clearly measurement errors or artificial anomalies.\n\n\nCategorical data\n\ndf_char &lt;- df[sapply(df, function(x) is.character(x) || is.factor(x) )]\ndf_l &lt;- df_char %&gt;% pivot_longer(cols = 1:7, names_to = \"variables\", values_to = \"values\")\n\n\n  df_l %&gt;%  ggplot(aes(x = factor(values))) + geom_bar() +\n  facet_wrap(~ variables, scales = \"free_y\") +\n  labs(x=\"\", y = \"\") + \n  coord_flip() \n\n\n\n\n\n\n\n\nThe number of individuals differs across the categorical features except for sex. The largest number of measured penguins comes from the Biscoe island.\n\nSpecies vs Island\n\np &lt;- df %&gt;% ggplot(aes(island, fill = species)) + geom_bar(position = \"stack\")\np + labs(x = \"Island\", y = \"The number of Penguins\") + theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\nWe can observe distinct habitat differences among species. Chinstrap and Gentoo penguins are found mainly on Biscoe and Dream islands, respectively, whereas Adelie penguins inhabit all three islands.\n\n\n\nPair plot of numeric data\n\ncor_mat &lt;- cor(numeric_df[-5], use = \"complete.obs\")\ncorrplot(cor_mat, \n         method = \"color\",\n         type = \"upper\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 40)\n\n\n\n\n\n\n\n\nThere are clear correlations among morphological variables. In particular, the correlation between body mass and flipper length appears to be high.\n\nmodel &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, data = df)\nvif(model)\n\n   bill_length_mm     bill_depth_mm flipper_length_mm \n         1.811190          1.312078          2.142848 \n\n\nHowever, the VIF values are all below 5, indicating that collinearity is negligible.\n\n\nThe relationship between flipper length and weight\n\np1 &lt;- df %&gt;% ggplot(aes(x = body_mass_g, y = flipper_length_mm, color = species)) + geom_point() +\n  labs(x = \"Weight (g)\", y = \"Flipper length (mm)\") + theme_minimal(base_size = 14)\n\np2 &lt;- df %&gt;% ggplot(aes(x = body_mass_g, y = flipper_length_mm, color = sex)) + geom_point() +\n  labs(x = \"Weight (g)\", y = \"Flipper length (mm)\") + theme_minimal(base_size = 14)\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\nWhile there is a clear relationship between flipper length and weight, differences between sexes and among species are not easily distinguishable.\n\n\nPair plot for numerical data\n\ndf01 &lt;- data.frame(species = df$species, numeric_df)\ndf01 %&gt;% ggpairs(ggplot2::aes(color = species, alpha = 0.4))\n\n\n\n\n\n\n\n\nThe ggpairs() covers most of preliminary examinations we have done up to this point, making it useful for quickly grasping an overall picture of the data.\n\n\n\nAnalytical methods\n\nModels\nWe used the classification models listed below. Except for selecting the value of k in kNN, we did not extensively tune hyperparameters. Our assumption was that if a model is well-suited to the data, it can still perform reasonably well with default settings. Therefore, the hyperparameters used here are essentially the default values, which are typically chosen to be broadly effective. Thus, the performance comparisons presented below are based on these default hyperparameter settings.\n\nLogistic regression models with Losso, Ridge, and Elastic net regularizations\nDecision Tree\nNaive Bayes\nK-Nearest Neighbors (KNN)\nSupport Vector Machine (SVM) (Linear)\nSupport Vector Machine (KSVM) (Radial Basis kernel “Gaussian”)\nRandom Forest\nBagging\nXGBoost\n\n\nFor each model, the workflow is as follows:\n\nModeling\nPrediction\nEvaluation\n\n\nConfusion matrix\nMetrics: accuracy, precision, recall, F1-score\nROC and AUC\n\n\n\n\nLoading libraries for machine learning\n\np_load(caret, rpart, rpart.plot, e1071, class, kernlab, MLmetrics,\n       randomForest, ipred, xgboost, glmnet, pROC)\n\n\n\nConvert data type of species from character to factor\nSince R does not automatically treat character variables as categorical, we need to convert character columns to factors before analysis.\n\ndf &lt;- df %&gt;%\n  mutate(across(where(is.character), as.factor))\n\n\n\nLabel Encoding and Standardization\nBecause data standardization is essential for SVM and kNN, and also recommended for logistic regression, we created an additional dataset in which all features were encoded and scaled.\n\nStandardization\n\n# df0 &lt;- df %&gt;% mutate_if(is.numeric, ~scale(.))\ndf0 &lt;- df %&gt;% mutate_if(is.numeric, \\(x)scale(x))\n\n\n\nLabel Encoding\nLabel encoding is also essential for SVM and kNN.\n\ndf1 &lt;- df0[-1] # drop target column\ndummy &lt;- dummyVars(~ ., data = df1)\ndummy_df &lt;- predict(dummy, newdata = df1)\ndf_svm_knn &lt;- cbind(df[1], dummy_df)\n\n\n\n\nPartitioning\nSplitting the dataset into training and test sets is an essential step for a machine learning pipeline. Although several methods are available across different libraries, we use createDataPartition() from the caret library.\n\nThe dataset for the tree-based models and Naive Bayes.\n\n\nset.seed(123)\nsample &lt;- createDataPartition(df$species, p = 0.7, list = FALSE)\ntrain &lt;- df[sample, ]\ntest &lt;- df[-sample, ]\n\n\nThe datasets for SVM, kNN and Logistic Regression models.\n\n\nset.seed(223)\nsample &lt;- createDataPartition(df_svm_knn$species, p = 0.7, list = FALSE)\ntrain_svmknn &lt;- df_svm_knn[sample, ]\ntest_svmknn &lt;- df_svm_knn[-sample, ]\n\n\n\n\nModeling\n\nDecision Tree, Naive Bayes, Random Forest, Bagging, XGBoost\n\nDataset: df, train, test\n\n\nDecision Tree\n\n#model_dt &lt;- rpart(\n#  species ~ ., data = train, method = \"class\",\n#  control = rpart.control(cp = 0.01, minsplit = 10, maxdepth = 5)\n#)\nmodel_dt &lt;- rpart(\n  species ~ ., data = train, method = \"class\"\n)\n\n\n\nNaive Bayes\nNaive Bayes assumes that all predictors are conditionally independent, an assumption that is violated when predictors are highly correlated. Typically, |r| &lt; 0.7 is considered acceptable for this model. Because the correlation between body mass and flipper length exceeds 0.7, this may reduce reliability of the analysis.\n\nmodel_bayes &lt;- naiveBayes(species ~ ., data = train, laplace = 1)\n\n\n\nRandom Forest\n\nset.seed(123)\nmodel_rf &lt;- randomForest(species ~., data = train, \n                        ntree = 500, mtry = 6, importance = TRUE, \n                        na.action = na.roughfix,replace = FALSE)\n\nHere,\n\nntree: the number of trees in the forest. Default value is 500.\n‘mtry’: the number of variables randomly sampled at each split, which controls tree diversity.\nimportance computes variable importance measures after training.\nna.action = na.roughfix handles missing values. It replaces NA with median for numeric variables and mode for factors.\nreplace controls whether bootstrap sampling is used.\n\n\n\nBagging\n\nset.seed(123)\nmodel_bg &lt;- bagging(species ~., data = train)\n\n\n\nXGBoost\n\nxgboost() requires numerical data in matrix form.\n\ndoes not assume intercept\nassume that the labels starts from 0\n\nmodel.matrix(() converts a model formula and data frame into a numerical design matrix.\n\nConverts categorical variables (factors) into dummy variables\nAutomatically remove the response variable (dependent or target variable)\n\n\n\nset.seed(123)\nX &lt;- model.matrix(species ~ . - 1, data = train) # remove intercept\ny &lt;- as.numeric(train$species) - 1 # the labeles starts from 0\n\nmodel_xg &lt;- xgboost(\n    data = X, \n    label = y, \n    nrounds = 10,\n    objective = \"multi:softprob\",\n    num_class = length(unique(y))\n    )\n\n[1] train-mlogloss:0.868836 \n[2] train-mlogloss:0.728109 \n[3] train-mlogloss:0.629022 \n[4] train-mlogloss:0.557720 \n[5] train-mlogloss:0.500952 \n[6] train-mlogloss:0.457259 \n[7] train-mlogloss:0.418241 \n[8] train-mlogloss:0.383407 \n[9] train-mlogloss:0.359887 \n[10]    train-mlogloss:0.337747 \n\n\n\n\n\nLogistic, kNN and SVM\n\nDataset: df_svm_knn, train_svmknn, test_svmknn\n\n\nLogistic regression model with Losso, Ridge, and Elastic net regularizations\n\n‘cv.glmnet’ assume a numerical matrix as input.\n\nHowever, it does not need to start the labels from 0\nAlso, it can include intercept by default.\n\n\n\nX_lg &lt;- model.matrix(species ~ ., train_svmknn) \ny_lg &lt;- train_svmknn$species\n\ncv_fit &lt;- cv.glmnet(\n    X_lg, y_lg,\n    family = \"multinomial\",\n    type.measure = \"class\",\n    nfolds = 5,\n    alpha = 0.5      # 1 = LASSO, 0 = Ridge 0.5 = Elastic net\n)\n\n# Best model\nbest_lambda &lt;- cv_fit$lambda.min\n\n# Fit final model\nmodel_lg &lt;- glmnet(X_lg, y_lg, family = \"multinomial\", \n                   alpha = 0.5, lambda = best_lambda)\n\n\n\nkNN\nThe best k is estimated.\n\nset.seed(123)\n\nk &lt;- seq(1, 21, by = 2)\ntune_grid &lt;- expand.grid(k = k)\n\nknn_tune &lt;- train(species ~., data = train_svmknn, method = \"knn\", \n                  trControl = trainControl(method = \"cv\", number = 5),\n                  tuneGrid = tune_grid\n                  )\n\nprint(paste0(\"k = \", knn_tune$bestTune))\n\n[1] \"k = 19\"\n\n\n\ntrain_knn &lt;- train_svmknn[-1] # Remove target\ntest_knn &lt;- test_svmknn[-1] # Remove target\n\nmodel_knn &lt;- knn(train = train_knn, test = test_knn, \n                 cl = train_svmknn$species, k = knn_tune$bestTune)\n\n\n\nSVM\nWe tested two types of SVM kernels: the linear kernel and the RBF kernel, with the latter serving as a non-linear alternative.\n\ntrain_svmknn$species &lt;- as.factor(train_svmknn$species)\nmodel_svm &lt;- svm(species ~ ., data = train_svmknn, kernel=\"linear\")\n\n\n\nKSVM\n\nmodel_ksvm &lt;- ksvm(species~., data = train_svmknn, kernel = \"rbfdot\", \n                   prob.model = TRUE)\n\n\n\n\n\nFeature Importance Calculation\nThe variable-importance results from the three models, Decision Tree, Random Forest, and XGBoost, consistently indicate that the island variable is most important predictor.\n\nDecision tree\n\n\nimp &lt;- model_dt$variable.importance\nbarplot(sort(imp, decreasing = TRUE), las = 2, \n        main = \"Decision Tree\")\n\n\n\n\n\n\n\n\n\nRandom Forest\n\n\nvarImpPlot(model_rf, main = \"Random Forest\")\n\n\n\n\n\n\n\n\n\nXGBoost\n\n\nimp &lt;- xgb.importance(feature_names = colnames(X), model = model_xg)\nxgb.plot.importance(imp[1:10], main = \"XGBBoost\")\n\n\n\n\n\n\n\n\n\n\nThe decision tree figure\n\nrpart.plot(model_dt)\n\n\n\n\n\n\n\n\nThe decision tree plot shows that the model appropriately classified Gentoo, but struggled to distinguish Chinstrap from Adelie. For example, Chinstrap penguins are not found on Torgensen island.\n\n\nPrediction\n\nDecision Tree\n\npred_dt &lt;- predict(model_dt, test, type = \"class\")\n\n\n\nNaive Bayes\n\npred_nb &lt;- predict(model_bayes, test)\n\n\n\nRandom Forest\n\npred_rf &lt;- predict(model_rf, test)\n\n\n\nBagging\n\npred_bg &lt;- predict(model_bg, test)\n\n\n\nXGBoost\n\nX_test  &lt;- model.matrix(species ~ . - 1, data = test)\ny_test  &lt;- as.numeric(test$species) - 1\n\n# returns a flatter vector of probabilities\npred_prob_xg &lt;- predict(model_xg, X_test) \n# comvert it into a matrix form\npred_prob_xg01 &lt;- matrix(pred_prob_xg, ncol = length(unique(y)), \n                         byrow = TRUE)\n# convert into labels in a vector.\npred_class_xg &lt;- max.col(pred_prob_xg01) - 1 \n\n\n\nLogistic models\n\nx_test &lt;- model.matrix(species ~ ., data = test_svmknn)\ny_test &lt;- as.numeric(test$species) \n\npred_class_lg &lt;- predict(model_lg, x_test, type = \"class\") \npred_prob_lg &lt;- predict(model_lg, x_test, type = \"response\")\n\n\n\nkNN\n\npred_knn &lt;- model_knn\n\n\n\nSVM\n\npred_svm &lt;- predict(model_svm, test_svmknn)\n\n\n\nKSVM\n\npred_ksvm &lt;- predict(model_ksvm, test_svmknn)"
  },
  {
    "objectID": "penguin.html#results-evaluation",
    "href": "penguin.html#results-evaluation",
    "title": "Classification of Penguins species using Machine Learning Models",
    "section": "Results: Evaluation",
    "text": "Results: Evaluation\n\nConfusion matrix\nCreate a list of confusion matrices for each model.\n\nclass_names &lt;- levels(train$species)\ntrue_label_xg  &lt;- class_names[y_test]\npred_label_xg  &lt;- class_names[pred_class_xg + 1]\n\npred_models &lt;- list(pred_dt, pred_nb, pred_rf, pred_bg, \n                    pred_label_xg,  pred_class_lg, pred_knn, \n                    pred_svm, pred_ksvm)\nmodel_names &lt;- c(\"Decision Tree\", \"Naive Bayes\", \"Random Forest\", \n                 \"Bagging\", \"XGBoost\", \"Logistic\", \n                 \"kNN\", \"SVM\", \"KSVM\")\n\ntable_list &lt;- map(pred_models, \\(pred){\n  actual_class &lt;- test$species\n  if (identical(pred, pred_class_lg) |\n      identical(pred, pred_knn) |\n      identical(pred, pred_svm) |\n      identical(pred, pred_ksvm)) {\n    actual_class &lt;- test_svmknn$species\n  }\n  \n  if(identical(pred, pred_label_xg)){\n    actual_class &lt;- true_label_xg\n  }\n  tb &lt;- table(pred, actual_class)\n  df_tb &lt;- tb %&gt;% as.data.frame()\n  colnames(df_tb) &lt;- c(\"predicted\", \"actual\", \"freq\")\n  df_tb\n})\nnames(table_list) &lt;- model_names\n\nCreate a list of confusion matrix plots for each model.\n\nplot_list &lt;- map(model_names, \\(ml){\n  df10 &lt;- table_list[[ml]]\n  df10 %&gt;% \n  ggplot(aes(x = actual, y = predicted, fill = freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = freq), size = 5) +\n  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n  scale_y_discrete(limits = rev) +        # reverse y-axis\n  scale_x_discrete(position = \"top\") +    # move x-axis to top\n  labs(x = ml, y = \"Predicted\") + \n  theme_minimal(base_size = 14) + \n  theme(legend.position=\"none\") \n})\n\nUse do.call() to call a function and pass its arguments as a list for creating confusion matrix plots.\n\ndo.call(grid.arrange, c(plot_list, ncol = 3))\n\n\n\n\n\n\n\n\nThe figures show that the Logistic Regression model and SVM models perform better than the other models.\n\n\nAccuracy, CE and F1\n\nAccuracy\n\nAccuracy = (Number of corect predictions) / (Total number of predictions)\nEasy to understand, but misleading with imbalanced classes.\n\nF1 Score\n\nF1 = 2 x (Precision x Recall) / (Presicion + Recall)\nPrecision = (Correct positive predictions) / (Total predicted positives)\nRecall: (Correct positive predictions) / (Total actural positives)\nUseful when classes are imbalanced\n\nClassification Error (CE)\n\nCE = 1 - Accuracy\n\n\n\n# Function to select correct actual labels per model\nget_actual &lt;- function(pred_vec) {\n  if (identical(pred_vec, pred_class_lg) |\n      identical(pred_vec, pred_knn) |\n      identical(pred_vec, pred_svm) |\n      identical(pred_vec, pred_ksvm)) {\n    return(test_svmknn$species)\n  } else if (identical(pred_vec, pred_label_xg)) {\n    return(true_label_xg)\n  } else {\n    return(test$species)\n  }\n}\n\n# Compute results programmatically\nresults_df &lt;- imap_dfr(pred_models, \\(pred, i) {\n\n  actual_class &lt;- get_actual(pred)\n\n  # Ensure factors have same levels\n  pred_vec &lt;- factor(pred, levels = levels(actual_class))\n\n  ac  &lt;- Accuracy(pred, actual_class) %&gt;% round(3)\n  f1  &lt;- F1_Score(pred, actual_class) %&gt;% round(3)\n  ce  &lt;- round(1 - ac, 3)\n\n  tibble(\n    Model = model_names[i],\n    Accuracy = ac,\n    F1 = f1,\n    CE = ce\n  )\n})\n\n\nresults_df %&gt;% arrange(-Accuracy)\n\n# A tibble: 9 × 4\n  Model         Accuracy    F1    CE\n  &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SVM              0.88  0.863 0.12 \n2 Logistic         0.875 0.857 0.125\n3 KSVM             0.812 0.774 0.188\n4 XGBoost          0.772 0.73  0.228\n5 Random Forest    0.768 0.737 0.232\n6 kNN              0.768 0.733 0.232\n7 Bagging          0.758 0.725 0.242\n8 Decision Tree    0.725 0.655 0.275\n9 Naive Bayes      0.658 0.635 0.342\n\n\nBased on Accuracy, F1, and CE, SVM is the best-performing model, followed by Logistic Regression.\n\n\nROC and AUC\nThe Receiver Operating Characteristic (ROC) curve illustrates the performance of a binary classifier across all possible threshold values. The curve depicts the trade-off between sensitivity (True Positive Rate, TPR) and 1 − specificity (False Positive Rate, FPR).\nFor multiclass classification, we applied a one-vs-rest (OvR) approach, creating a binary dataset for each penguin species. For example, in the Adelie penguins classifier, all Adelie penguins are labeled 1, while the other penguins are labeled 0. This allows us to compute an ROC curve and corresponding AUC value for each species.\nThe Area Under the Curve (AUC) quantifies the area under the ROC curve, summarizing the model’s overall ability to discriminate between classes.\n\nROC using pROC library\n\n# p_load(pROC)\n\n\n# prob_dt &lt;- predict(model_dt, test, type = \"prob\")\n\n\n#model_svm &lt;- svm(species ~ ., data = train_svmknn, kernel=\"linear\", \n#                 probability = TRUE)\n#pred_svm &lt;- predict(model_svm, test_svmknn, probability = TRUE)\n#prob_svm &lt;- attr(pred_svm, \"probabilities\")\n#\n#mc_roc &lt;- multiclass.roc(test$species, prob_svm)\n#\n\n\n\nONE-vs-REST\n\nProbability\n\n# decision tree\nprob_dt &lt;- predict(model_dt, test, type = \"prob\")\n\n# bayes\nprob_bayes &lt;- predict(model_bayes, test, type = \"raw\")\n\n# Random forest\nprob_rf &lt;- predict(model_rf, test, type = \"prob\")\n\n# Bagging\nprob_bg &lt;- predict(model_bg, test, type = \"prob\")\n\n# XGBoost\npred_prob_xg &lt;- predict(model_xg, X_test)\nnum_class &lt;- length(levels(train$species))\nprob_xg &lt;- matrix(pred_prob_xg, ncol = num_class, byrow = TRUE)\ncolnames(prob_xg) &lt;- levels(train$species)\n\n# Logistic model\nprob_list &lt;- predict(model_lg, x_test, type = \"response\")\nprob_lg &lt;- prob_list[, , 1]\ncolnames(prob_lg) &lt;- levels(train_svmknn$species)\n\n# knn\nmodel_knn3 &lt;- knn3(species ~ ., data = train)\nprob_knn &lt;- predict(model_knn3, test, type = \"prob\")\n\ntrain_svmknn$species &lt;- as.factor(train_svmknn$species)\n\n# svm\nmodel_svm &lt;- svm(species ~ ., data = train_svmknn, kernel=\"linear\",\n                 probability = TRUE)\npred_svm &lt;- predict(model_svm, test_svmknn, probability = TRUE)\nprob_svm &lt;- attr(pred_svm, \"probabilities\")\n\n# ksvm\nmodel_ksvm &lt;- ksvm(species ~ ., data = train_svmknn, \n                   kernel = \"rbfdot\",  prob.model = TRUE)\nprob_ksvm &lt;- predict(model_ksvm, test_svmknn, type = \"probabilities\")\n\n\n\nROC\nCalculate the ROC curves for all models separately for each penguin species.\n\nmodels &lt;- list(\n  dt   = prob_dt,\n  bayes = prob_bayes,\n  knn  = prob_knn,\n  svm  = prob_svm,\n  ksvm = prob_ksvm,\n  random = prob_rf,\n  bagging = prob_bg,\n  xgb = prob_xg,\n  logistic = prob_lg\n)\n\ntruth &lt;- test_svmknn$species %&gt;% as.factor() # must be factor\nclasses &lt;- levels(test_svmknn$species %&gt;% as.factor())\nroc_list &lt;- list() \n\nfor (m_name in names(models)){\n  prob_df &lt;- models[[m_name]] %&gt;% as.data.frame()\n  for (cls in classes){\n    binary_truth &lt;- ifelse(truth == cls, 1, 0)\n    roc_obj &lt;- roc(binary_truth, prob_df[[cls]], quiet = TRUE)\n    roc_list[[paste(m_name, cls, sep = \"_\")]] &lt;- roc_obj\n  }\n}\n\nConvert the roc_list into data frames and visualize them as plots.\n\nroc_df &lt;- map_df(names(roc_list), \\(nm) {\n  roc_obj &lt;- roc_list[[nm]]\n  df &lt;- data.frame(\n    specificity = roc_obj$specificities,\n    sensitivity = roc_obj$sensitivities,\n    name = nm\n  )\n  df\n})\n\nroc_df &lt;- roc_df %&gt;%\n  separate(name, into = c(\"Model\", \"Class\"), sep = \"_\")\n\nggplot(roc_df, aes(x = 1 - specificity, y = sensitivity, \n                   color = Model)) +\n  geom_line(size = 1) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", \n              color = \"gray\") +\n  facet_wrap(~ Class) +\n  theme_minimal(base_size = 14) +\n  labs(\n    title = \"ROC Curves by Model and Class\",\n    x = \"False Positive Rate\",\n    y = \"True Positive Rate\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nApparently, Logistic Regression and SVM performs better across all penguin species.\n\n\nAUC\nExtract the AUC values for each model from roc_list and compile them into a data frame.\n\nauc_values &lt;- map_dbl(roc_list, \\(x)x$auc) %&gt;% round(3)\nauc_df &lt;- data.frame(models = auc_values %&gt;% names, \n                     AUC = auc_values %&gt;% as.numeric())\n\nVisualize the AUC values for all models.\n\n# Calculate average AUC values by models\n\nauc_df &lt;- auc_df %&gt;% \n  mutate(label = auc_df$models) %&gt;%\n  separate(models, into = c(\"model\", \"class\"), sep = \"_\") %&gt;%\n  group_by(model) %&gt;% \n  mutate(mean_AUC = mean(AUC)) %&gt;% \n  ungroup()\n\n# Order the MODEL factor by mean_AUC (this controls legend order)\nauc_df$model &lt;- factor(auc_df$model, levels = auc_df %&gt;% \n                         distinct(model, mean_AUC) %&gt;% \n                         arrange(-mean_AUC) %&gt;% \n                         pull(model))\n\n# Order the bar labels (x-axis)\nauc_df &lt;- auc_df %&gt;% \n  arrange(mean_AUC, AUC, model) %&gt;% \n  mutate(label = factor(label, levels = label))\n\n# Plot\nggplot(auc_df, aes(x = label, y = AUC, fill = model)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() +\n  theme(axis.title.y = element_blank())\n\n\n\n\n\n\n\n\nThis figure also shows that Logistic Regression and SVM models outperform the other models."
  },
  {
    "objectID": "penguin.html#conclusion",
    "href": "penguin.html#conclusion",
    "title": "Classification of Penguins species using Machine Learning Models",
    "section": "Conclusion",
    "text": "Conclusion\nPredicting species from habitat, morphological traits, and other features was possible with high accuracy. The Logistic Regression and SVM models achieved accuracies greater than 0.87, with average AUC values for each species exceeding 0.96. In contrast, other models, including tree-based, distance-based and probalistic approaches, were less effective for these predictions.\nEven so, compared to the other species, the best-performing models still struggled to distinguish Adelie penguins from the other two species. Considering the variable importance indicated by the tree-based models, this difficulty may be related to their habitats: while Chinstrap and Gentoo penguins inhabit specific islands, Adelie are found on all three islands."
  }
]